import cv2
import mediapipe as mp
import numpy as np
import av
import math
import time
import queue
import os
from pathlib import Path
import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, RTCConfiguration

# ========= ê¸°ë³¸ ì„¤ì • =========
st.set_page_config(page_title="AI ìë™ ì´¬ì˜ê¸°", layout="centered")

# ì €ì¥ í´ë” í™•ì‹¤í•˜ê²Œ ìƒì„±
SAVE_DIR = Path("captures")
SAVE_DIR.mkdir(parents=True, exist_ok=True)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "snapshot" not in st.session_state:
    st.session_state.snapshot = None

# STUN ì„œë²„ (ë°°í¬ í•„ìˆ˜)
RTC_CONFIGURATION = RTCConfiguration(
    {"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}
)

# Mediapipe ì´ˆê¸°í™”
mp_face = mp.solutions.face_detection

# ========= ìœ í‹¸ í•¨ìˆ˜ =========
def calc_roll_angle(detection, width, height):
    kp = detection.location_data.relative_keypoints
    left_eye = kp[0]
    right_eye = kp[1]
    x1, y1 = left_eye.x * width, left_eye.y * height
    x2, y2 = right_eye.x * width, right_eye.y * height
    angle = math.degrees(math.atan2(y2 - y1, x2 - x1))
    return angle

# ========= ì˜ìƒ ì²˜ë¦¬ í´ë˜ìŠ¤ =========
class FaceAngleProcessor(VideoProcessorBase):
    def __init__(self):
        self.ref_angle = None
        self.face_detector = mp_face.FaceDetection(model_selection=0, min_detection_confidence=0.5)
        self.result_queue = queue.Queue()
        
        # ì´¬ì˜ ê´€ë ¨ ë³€ìˆ˜
        self.match_start_time = None
        self.last_capture_time = 0
        self.flash_frame = 0

    def recv(self, frame: av.VideoFrame) -> av.VideoFrame:
        img = frame.to_ndarray(format="bgr24")
        img = cv2.flip(img, 1) # ê±°ìš¸ ëª¨ë“œ
        h, w, _ = img.shape
        
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        results = self.face_detector.process(img_rgb)
        
        current_angle = 0.0
        status_text = "Looking..."
        color = (0, 0, 255) # ë¹¨ê°•

        if results.detections:
            detection = results.detections[0]
            current_angle = calc_roll_angle(detection, w, h)
            
            # ëª¨ë°”ì¼ Zê°’ ë³´ì • (ë‹¨ìˆœí™”)
            current_z = (detection.location_data.relative_keypoints[2].y - 
                         detection.location_data.relative_keypoints[0].y) * 10 
            # ì‹¤ì œë¡œëŠ” Roll ê°ë„ ê¸°ì¤€ìœ¼ë¡œ í•¨ (ì§ˆë¬¸ì ì˜ë„ ë°˜ì˜)
            # ì—¬ê¸°ì„œëŠ” 'ê°ë„' ìì²´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ íŒë³„í•©ë‹ˆë‹¤.
            
            status_text = f"Angle: {current_angle:.1f}"

            # â˜… ì¡°ê±´ ì²´í¬ (ê°ë„ ì°¨ì´ê°€ ì‘ìœ¼ë©´) â˜…
            # ê¸°ì¤€ ê°ë„ê°€ ì—†ìœ¼ë©´ 0ë„(ì •ë©´)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•¨
            target = self.ref_angle if self.ref_angle is not None else 0
            diff = abs(current_angle - target)
            
            if diff < 5.0:  # 5ë„ ì´ë‚´ë©´ OK
                color = (0, 255, 0) # ì´ˆë¡
                status_text = "HOLD ON!"
                
                if self.match_start_time is None:
                    self.match_start_time = time.time()
                
                # 1ì´ˆ ìœ ì§€ ì‹œ ì´¬ì˜
                if time.time() - self.match_start_time > 1.0:
                    if time.time() - self.last_capture_time > 3.0:
                        
                        # [1] ì„œë²„ í´ë”ì— ë¬´ì¡°ê±´ ì €ì¥ (ë°±ì—…ìš©)
                        ts = int(time.time())
                        filename = SAVE_DIR / f"Auto_Shot_{ts}.jpg"
                        # OpenCVëŠ” BGR ì´ë¯¸ì§€ë¥¼ ì €ì¥í•¨
                        cv2.imwrite(str(filename), img)
                        print(f"ğŸ’¾ ì„œë²„ ì €ì¥ ì™„ë£Œ: {filename}")
                        
                        # [2] í™”ë©´ìœ¼ë¡œ ì „ì†¡ (RGB ë³€í™˜)
                        send_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                        self.result_queue.put(send_img)
                        
                        self.last_capture_time = time.time()
                        self.flash_frame = 5
            else:
                self.match_start_time = None
        
        # í”Œë˜ì‹œ íš¨ê³¼
        if self.flash_frame > 0:
            self.flash_frame -= 1
            cv2.rectangle(img, (0,0), (w,h), (255,255,255), -1) # í•˜ì–€ í™”ë©´
            status_text = "CAPTURED!"
            
        # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
        cv2.rectangle(img, (0,0), (w,h), color, 10)
        cv2.putText(img, status_text, (20, 80), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,0,0), 5)
        cv2.putText(img, status_text, (20, 80), cv2.FONT_HERSHEY_SIMPLEX, 1.5, color, 2)
            
        return av.VideoFrame.from_ndarray(img, format="bgr24")

# ========= ë©”ì¸ UI =========
def main():
    st.title("ğŸ“¸ AI ìë™ ì´¬ì˜ê¸°")
    st.warning("ğŸ‘‡ ì‚¬ì§„ì´ ì°íˆë©´ í™”ë©´ ì•„ë˜ì— ë‚˜íƒ€ë‚©ë‹ˆë‹¤! ìŠ¤í¬ë¡¤ì„ ë‚´ë ¤ë³´ì„¸ìš”.")

    col1, col2 = st.columns([1, 1])

    with col1:
        st.subheader("1. ê¸°ì¤€ ì‚¬ì§„ (ì„ íƒ)")
        uploaded_file = st.file_uploader("ì—†ìœ¼ë©´ ì •ë©´(0ë„)ì´ ê¸°ì¤€ì´ ë©ë‹ˆë‹¤.", type=['jpg', 'png'])
        ref_angle_val = 0.0
        if uploaded_file:
            # (ì‚¬ì§„ ë¶„ì„ ë¡œì§ ìƒëµ - íŒŒì¼ë§Œ ìˆìœ¼ë©´ 0ë„ë¡œ ê°€ì •í•˜ê±°ë‚˜ ë³„ë„ ë¶„ì„ ê°€ëŠ¥)
            st.success("ê¸°ì¤€ ì‚¬ì§„ ì„¤ì •ë¨!")

    with col2:
        st.subheader("2. ì´¬ì˜ í™”ë©´")
        ctx = webrtc_streamer(
            key="camera",
            video_processor_factory=FaceAngleProcessor,
            rtc_configuration=RTC_CONFIGURATION,
            media_stream_constraints={"video": {"facingMode": "user"}, "audio": False},
            async_processing=True
        )
        if ctx.video_processor:
            ctx.video_processor.ref_angle = ref_angle_val

        # [í•µì‹¬] ì‹¤ì‹œê°„ìœ¼ë¡œ ì‚¬ì§„ ë°°ë‹¬ ê¸°ë‹¤ë¦¬ê¸°
        if ctx.state.playing:
            if ctx.video_processor:
                try:
                    result = ctx.video_processor.result_queue.get(timeout=0.1)
                    if result is not None:
                        st.session_state.snapshot = result
                        st.rerun() # í™”ë©´ ìƒˆë¡œê³ ì¹¨!
                except queue.Empty:
                    pass

    # ------------------------------------------------
    # ì—¬ê¸°ê°€ ì‚¬ì§„ ë‚˜ì˜¤ëŠ” ê³³ì…ë‹ˆë‹¤ (í™”ë©´ í•˜ë‹¨)
    # ------------------------------------------------
    st.markdown("---")
    if st.session_state.snapshot is not None:
        st.balloons()
        st.success("ğŸ“¸ ì°í˜”ìŠµë‹ˆë‹¤! ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì €ì¥í•˜ì„¸ìš”.")
        
        # ì‚¬ì§„ í‘œì‹œ
        st.image(st.session_state.snapshot, caption="ì¸ìƒìƒ· ê±´ì§", use_container_width=True)
        
        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
        img_bgr = cv2.cvtColor(st.session_state.snapshot, cv2.COLOR_RGB2BGR)
        ret, buffer = cv2.imencode('.jpg', img_bgr)
        if ret:
            st.download_button(
                label="ğŸ“¥ ë‚´ í° ê°¤ëŸ¬ë¦¬ì— ì €ì¥í•˜ê¸°",
                data=buffer.tobytes(),
                file_name=f"Selfie_{int(time.time())}.jpg",
                mime="image/jpeg",
                type="primary"
            )
            
        if st.button("ğŸ”„ ë‹¤ì‹œ ì°ìœ¼ëŸ¬ ê°€ê¸°"):
            st.session_state.snapshot = None
            st.rerun()

if __name__ == "__main__":
    main()


