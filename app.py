import time
import math
from io import StringIO

import av
import cv2
import mediapipe as mp
import numpy as np
import streamlit as st
from streamlit_webrtc import (
    webrtc_streamer,
    WebRtcMode,
    RTCConfiguration,
    VideoTransformerBase,
)

# ========= Mediapipe ì„¤ì • =========
mp_face = mp.solutions.face_detection

# WebRTC STUN ì„œë²„ ì„¤ì • (Cloud í™˜ê²½ì—ì„œ í•„ìˆ˜)
RTC_CONFIGURATION = RTCConfiguration(
    {
        "iceServers": [
            {"urls": ["stun:stun.l.google.com:19302"]},
        ]
    }
)


# ========= ìœ í‹¸ í•¨ìˆ˜ë“¤ =========
def calc_roll_angle_from_detection(detection, width, height):
    """
    Mediapipe FaceDetection ê²°ê³¼ì—ì„œ ì–¼êµ´ ê¸°ìš¸ê¸°(roll angle)ë¥¼ ê³„ì‚°.
    ë‘ ëˆˆ ìœ„ì¹˜ë¥¼ ì´ìš©í•´ì„œ ê°ë„ êµ¬í•¨.
    """
    keypoints = detection.location_data.relative_keypoints

    # LEFT_EYE = 0, RIGHT_EYE = 1
    left_eye = keypoints[0]
    right_eye = keypoints[1]

    x1, y1 = left_eye.x * width, left_eye.y * height
    x2, y2 = right_eye.x * width, right_eye.y * height

    dx = x2 - x1
    dy = y2 - y1

    angle_rad = math.atan2(dy, dx)
    angle_deg = math.degrees(angle_rad)

    return angle_deg


def analyze_reference_image(file):
    """
    ì—…ë¡œë“œ ê¸°ì¤€ ì‚¬ì§„ì—ì„œ ì–¼êµ´ì„ ì°¾ê³  ê°ë„ë¥¼ ê³„ì‚°í•´ì„œ ë°˜í™˜.
    ì‹¤íŒ¨ ì‹œ None.
    """
    file_bytes = np.asarray(bytearray(file.read()), dtype=np.uint8)
    img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)

    if img is None:
        st.error("ê¸°ì¤€ ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

    h, w, _ = img.shape
    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    with mp_face.FaceDetection(model_selection=0, min_detection_confidence=0.6) as detector:
        res = detector.process(rgb)

    if not res.detections:
        st.error("ê¸°ì¤€ ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return None

    detection = res.detections[0]
    angle = calc_roll_angle_from_detection(detection, w, h)
    return angle


def encode_image_to_png_bytes(img_bgr: np.ndarray) -> bytes:
    """BGR ì´ë¯¸ì§€ë¥¼ PNG ë°”ì´íŠ¸ë¡œ ì¸ì½”ë”©."""
    ok, buf = cv2.imencode(".png", img_bgr)
    if not ok:
        raise RuntimeError("ì´ë¯¸ì§€ ì¸ì½”ë”© ì‹¤íŒ¨")
    return buf.tobytes()


# ========= WebRTCìš© VideoTransformer =========
class FaceAngleTransformer(VideoTransformerBase):
    def __init__(self):
        # Mediapipe detector
        self.detector = mp_face.FaceDetection(
            model_selection=0,
            min_detection_confidence=0.6,
        )

        # ìƒíƒœ ê°’ë“¤
        self.ref_angle = None      # ê¸°ì¤€ ì‚¬ì§„ ê°ë„
        self.last_angle = None     # ìµœê·¼ í”„ë ˆì„ ê°ë„
        self.last_diff = None      # ê¸°ì¤€ê³¼ì˜ ì°¨ì´
        self.last_frame = None     # ìµœê·¼ í”„ë ˆì„ (BGR)

        # ë¡œê·¸ ê¸°ë¡ (ì‹œê°„, ê°ë„, ì°¨ì´)
        self.log = []

    def set_reference_angle(self, angle):
        self.ref_angle = angle

    def recv(self, frame: av.VideoFrame) -> av.VideoFrame:
        img = frame.to_ndarray(format="bgr24")
        self.last_frame = img.copy()

        img_h, img_w, _ = img.shape
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        res = self.detector.process(img_rgb)

        angle = None
        diff = None

        if res.detections:
            detection = res.detections[0]
            angle = calc_roll_angle_from_detection(detection, img_w, img_h)
            self.last_angle = angle

            # ê¸°ì¤€ ê°ë„ì™€ ì°¨ì´
            if self.ref_angle is not None:
                diff = angle - self.ref_angle
                self.last_diff = diff

            # í™”ë©´ì— ê·¸ë¦¬ê¸° (ë°•ìŠ¤ + í…ìŠ¤íŠ¸)
            relative_bbox = detection.location_data.relative_bounding_box
            x1 = int(relative_bbox.xmin * img_w)
            y1 = int(relative_bbox.ymin * img_h)
            w = int(relative_bbox.width * img_w)
            h = int(relative_bbox.height * img_h)

            cv2.rectangle(img, (x1, y1), (x1 + w, y1 + h), (0, 255, 0), 2)

            text = f"angle: {angle:.1f} deg"
            if diff is not None:
                text += f" | diff: {diff:+.1f} deg"

            cv2.putText(
                img,
                text,
                (x1, max(0, y1 - 10)),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.7,
                (0, 255, 0),
                2,
                cv2.LINE_AA,
            )

            # ë¡œê·¸ ì €ì¥
            self.log.append(
                {
                    "time": time.time(),
                    "angle": float(angle),
                    "diff": float(diff) if diff is not None else None,
                }
            )

        else:
            self.last_angle = None
            self.last_diff = None

        return av.VideoFrame.from_ndarray(img, format="bgr24")


# ========= Streamlit UI =========
def main():
    st.set_page_config(page_title="ì–¼êµ´ ê°ë„ ë¶„ì„ ë°ëª¨", layout="wide")
    st.title("ğŸ“· ì–¼êµ´ ê°ë„ ë¶„ì„ Â· ê¸°ì¤€ ì‚¬ì§„ê³¼ì˜ ìœ ì‚¬ë„ ì²´í¬")

    st.write(
        """
        - ì™¼ìª½ì—ì„œ **ê¸°ì¤€ ì‚¬ì§„**ì„ ì—…ë¡œë“œí•´ì„œ ê¸°ì¤€ ì–¼êµ´ ê°ë„ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.  
        - ì˜¤ë¥¸ìª½ì— ì¹´ë©”ë¼ë¥¼ ì¼œë©´ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°ë„ì™€ ê¸°ì¤€ ëŒ€ë¹„ ì°¨ì´ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  
        - ì•„ë˜ì—ì„œ **ìŠ¤ëƒ…ìƒ· ì €ì¥ / CSV ë‹¤ìš´ë¡œë“œ**ë„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        """
    )

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "snapshot_counter" not in st.session_state:
        st.session_state["snapshot_counter"] = 0
    if "last_snapshot_png" not in st.session_state:
        st.session_state["last_snapshot_png"] = None

    col_left, col_right = st.columns(2)

    # ---- 1ï¸âƒ£ ê¸°ì¤€ ì‚¬ì§„ ì—…ë¡œë“œ & ë¶„ì„ ----
    with col_left:
        st.subheader("1ï¸âƒ£ ê¸°ì¤€ ì‚¬ì§„ ì„¤ì •")

        uploaded_file = st.file_uploader(
            "ì–¼êµ´ì´ ì˜ ë‚˜ì˜¨ ê¸°ì¤€ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (jpg, png ë“±)",
            type=["jpg", "jpeg", "png"],
        )

        if uploaded_file is not None and st.button("ê¸°ì¤€ ì‚¬ì§„ ê°ë„ ë¶„ì„í•˜ê¸°"):
            angle = analyze_reference_image(uploaded_file)
            if angle is not None:
                st.session_state["ref_angle_value"] = angle
                st.success(f"ê¸°ì¤€ ì–¼êµ´ ê°ë„: {angle:.2f}Â°")

        if "ref_angle_value" in st.session_state:
            st.info(f"í˜„ì¬ ì €ì¥ëœ ê¸°ì¤€ ê°ë„: {st.session_state['ref_angle_value']:.2f}Â°")

    # ---- 2ï¸âƒ£ ì¹´ë©”ë¼ WebRTC ----
    with col_right:
        st.subheader("2ï¸âƒ£ ì¹´ë©”ë¼ë¡œ ì‹¤ì‹œê°„ ë¶„ì„")

        webrtc_ctx = webrtc_streamer(
            key="face-angle-demo",
            mode=WebRtcMode.SENDRECV,
            rtc_configuration=RTC_CONFIGURATION,
            media_stream_constraints={"video": True, "audio": False},
            video_transformer_factory=FaceAngleTransformer,
            async_processing=True,
        )

        angle_placeholder = st.empty()
        diff_placeholder = st.empty()

        if webrtc_ctx and webrtc_ctx.video_transformer:
            transformer: FaceAngleTransformer = webrtc_ctx.video_transformer  # type: ignore

            # ê¸°ì¤€ ê°ë„ ì£¼ì…
            if "ref_angle_value" in st.session_state:
                transformer.set_reference_angle(st.session_state["ref_angle_value"])

            if webrtc_ctx.state.playing:
                current_angle = transformer.last_angle
                current_diff = transformer.last_diff

                if current_angle is not None:
                    angle_placeholder.metric("í˜„ì¬ ì–¼êµ´ ê°ë„", f"{current_angle:.2f}Â°")
                else:
                    angle_placeholder.write("ì–¼êµ´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

                if current_diff is not None and transformer.ref_angle is not None:
                    diff_placeholder.metric(
                        "ê¸°ì¤€ ëŒ€ë¹„ ì°¨ì´",
                        f"{current_diff:+.2f}Â°",
                    )
                elif transformer.ref_angle is None:
                    diff_placeholder.write("ê¸°ì¤€ ê°ë„ê°€ ì•„ì§ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                else:
                    diff_placeholder.write("ì°¨ì´ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")

    # ---- 3ï¸âƒ£ ìŠ¤ëƒ…ìƒ· & CSV ë‹¤ìš´ë¡œë“œ ----
    st.subheader("3ï¸âƒ£ ìŠ¤ëƒ…ìƒ· ë° ê¸°ë¡ ì €ì¥")

    if "ref_angle_value" in st.session_state:
        st.write(f"ì‚¬ìš© ì¤‘ì¸ ê¸°ì¤€ ê°ë„: **{st.session_state['ref_angle_value']:.2f}Â°**")

    # ìœ„ì—ì„œ ë§Œë“  webrtc_ctx ê·¸ëŒ€ë¡œ ì¬ì‚¬ìš©
    transformer = None
    if webrtc_ctx and webrtc_ctx.video_transformer:
        transformer = webrtc_ctx.video_transformer  # type: ignore

    col1, col2 = st.columns(2)

    # ğŸ”¹ ì™¼ìª½: ìŠ¤ëƒ…ìƒ· ì €ì¥ + ë‹¤ìš´ë¡œë“œ
    with col1:
        if transformer is None:
            st.info("ìœ„ì˜ ì¹´ë©”ë¼ë¥¼ ë¨¼ì € ì¼œê³ , ì–¼êµ´ì´ ë³´ì´ë„ë¡ í•´ ì£¼ì„¸ìš”.")
        else:
            if st.button("í˜„ì¬ í™”ë©´ ìŠ¤ëƒ…ìƒ· ì €ì¥"):
                if transformer.last_frame is not None:
                    img_png = encode_image_to_png_bytes(transformer.last_frame)
                    st.session_state["last_snapshot_png"] = img_png
                    st.session_state["snapshot_counter"] += 1
                    st.success("ìŠ¤ëƒ…ìƒ·ì„ ì„ì‹œë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤. ì•„ë˜ì—ì„œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                else:
                    st.warning("í”„ë ˆì„ì´ ì•„ì§ ì—†ìŠµë‹ˆë‹¤. ì¹´ë©”ë¼ê°€ ì¼œì ¸ ìˆëŠ”ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”.")

        # ì €ì¥ëœ ìŠ¤ëƒ…ìƒ·ì´ ìˆìœ¼ë©´ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ í‘œì‹œ
        if st.session_state.get("last_snapshot_png") is not None:
            st.download_button(
                label=f"ë§ˆì§€ë§‰ ìŠ¤ëƒ…ìƒ· PNG ë‹¤ìš´ë¡œë“œ (#{st.session_state['snapshot_counter']})",
                data=st.session_state["last_snapshot_png"],
                file_name=f"snapshot_{st.session_state['snapshot_counter']}.png",
                mime="image/png",
            )

    # ğŸ”¹ ì˜¤ë¥¸ìª½: CSV ë¡œê·¸ ë‹¤ìš´ë¡œë“œ
    with col2:
        if transformer is None:
            st.info("ì¹´ë©”ë¼ê°€ ì¼œì§„ ì´í›„ì— ê°ë„ ê¸°ë¡ì´ ìŒ“ì…ë‹ˆë‹¤.")
        else:
            st.write("ì‹¤ì‹œê°„ ê°ë„ ê¸°ë¡ì„ CSVë¡œ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

            if transformer.log:
                csv_buffer = StringIO()
                csv_buffer.write("time,angle,diff\n")
                for row in transformer.log:
                    csv_buffer.write(
                        f"{row['time']},{row['angle']},{'' if row['diff'] is None else row['diff']}\n"
                    )

                csv_data = csv_buffer.getvalue()

                st.download_button(
                    label="ì¸¡ì • ê¸°ë¡ CSV ë‹¤ìš´ë¡œë“œ",
                    data=csv_data,
                    file_name="face_angle_log.csv",
                    mime="text/csv",
                )
            else:
                st.info("ì•„ì§ ê¸°ë¡ëœ ê°ë„ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤. ì¹´ë©”ë¼ë¥¼ ì¼œê³  ì–¼êµ´ì„ ë¹„ì¶°ë³´ì„¸ìš”.")


if __name__ == "__main__":
    main()