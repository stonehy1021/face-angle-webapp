import time
import math
from io import StringIO

import av
import cv2
import mediapipe as mp
import numpy as np
import streamlit as st
from streamlit_webrtc import (
    webrtc_streamer,
    WebRtcMode,
    RTCConfiguration,
    VideoTransformerBase,
)

# ========= Mediapipe ì„¸íŒ… =========
mp_face = mp.solutions.face_detection

# WebRTC STUN ì„œë²„ ì„¤ì • (ì™¸ë¶€ ì ‘ì†ìš©)
RTC_CONFIGURATION = RTCConfiguration(
    {
        "iceServers": [
            {"urls": ["stun:stun.l.google.com:19302"]},
        ]
    }
)


# ========= ìœ í‹¸ í•¨ìˆ˜ë“¤ =========
def calc_roll_angle_from_detection(detection, width, height):
    """
    Mediapipe FaceDetection ê²°ê³¼ì—ì„œ ì–¼êµ´ ê¸°ìš¸ê¸°(roll angle)ë¥¼ ê³„ì‚°.
    ì—¬ê¸°ì„œëŠ” ë‘ ëˆˆ ìœ„ì¹˜ë¥¼ ì´ìš©í•´ì„œ ê°ë„ êµ¬í•¨.
    """
    keypoints = detection.location_data.relative_keypoints

    # LEFT_EYE = 0, RIGHT_EYE = 1 (mediapipe docs ê¸°ì¤€)
    left_eye = keypoints[0]
    right_eye = keypoints[1]

    x1, y1 = left_eye.x * width, left_eye.y * height
    x2, y2 = right_eye.x * width, right_eye.y * height

    dx = x2 - x1
    dy = y2 - y1

    angle_rad = math.atan2(dy, dx)
    angle_deg = math.degrees(angle_rad)

    return angle_deg


def analyze_reference_image(file) -> float | None:
    """
    ì—…ë¡œë“œëœ ê¸°ì¤€ ì‚¬ì§„ì—ì„œ ì–¼êµ´ì„ ì°¾ê³  ê°ë„ë¥¼ ê³„ì‚°í•´ì„œ ë°˜í™˜.
    ì‹¤íŒ¨ ì‹œ None.
    """
    file_bytes = np.asarray(bytearray(file.read()), dtype=np.uint8)
    img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)

    if img is None:
        st.error("ê¸°ì¤€ ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

    h, w, _ = img.shape
    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    with mp_face.FaceDetection(model_selection=0, min_detection_confidence=0.6) as detector:
        res = detector.process(rgb)

    if not res.detections:
        st.error("ê¸°ì¤€ ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return None

    detection = res.detections[0]
    angle = calc_roll_angle_from_detection(detection, w, h)
    return angle


def encode_image_to_png_bytes(img_bgr: np.ndarray) -> bytes:
    """BGR ì´ë¯¸ì§€ë¥¼ PNG ë°”ì´íŠ¸ë¡œ ì¸ì½”ë”©."""
    ok, buf = cv2.imencode(".png", img_bgr)
    if not ok:
        raise RuntimeError("ì´ë¯¸ì§€ ì¸ì½”ë”© ì‹¤íŒ¨")
    return buf.tobytes()


# ========= WebRTCìš© VideoTransformer =========
class FaceAngleTransformer(VideoTransformerBase):
    def __init__(self):
        # Mediapipe detector
        self.detector = mp_face.FaceDetection(
            model_selection=0,
            min_detection_confidence=0.6,
        )

        # ìƒíƒœ ê°’ë“¤
        self.ref_angle: float | None = None   # ê¸°ì¤€ ì‚¬ì§„ ê°ë„
        self.last_angle: float | None = None  # ìµœê·¼ í”„ë ˆì„ ê°ë„
        self.last_diff: float | None = None   # ê¸°ì¤€ê³¼ì˜ ì°¨ì´
        self.last_frame: np.ndarray | None = None  # ìµœê·¼ í”„ë ˆì„ (BGR)

        # ë¡œê·¸ ê¸°ë¡ (ì‹œê°„, ê°ë„, ì°¨ì´)
        self.log = []

    def set_reference_angle(self, angle: float | None):
        self.ref_angle = angle

    def recv(self, frame: av.VideoFrame) -> av.VideoFrame:
        img = frame.to_ndarray(format="bgr24")
        self.last_frame = img.copy()

        img_h, img_w, _ = img.shape
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        res = self.detector.process(img_rgb)

        angle = None
        diff = None

        if res.detections:
            detection = res.detections[0]
            angle = calc_roll_angle_from_detection(detection, img_w, img_h)
            self.last_angle = angle

            # ê¸°ì¤€ ê°ë„ì™€ ì°¨ì´
            if self.ref_angle is not None:
                diff = angle - self.ref_angle
                self.last_diff = diff

            # í™”ë©´ì— ê·¸ë¦¬ê¸° (ë°•ìŠ¤ + í…ìŠ¤íŠ¸)
            relative_bbox = detection.location_data.relative_bounding_box
            x1 = int(relative_bbox.xmin * img_w)
            y1 = int(relative_bbox.ymin * img_h)
            w = int(relative_bbox.width * img_w)
            h = int(relative_bbox.height * img_h)

            cv2.rectangle(img, (x1, y1), (x1 + w, y1 + h), (0, 255, 0), 2)

            text = f"angle: {angle:.1f} deg"
            if diff is not None:
                text += f" | diff: {diff:+.1f} deg"

            cv2.putText(
                img,
                text,
                (x1, max(0, y1 - 10)),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.7,
                (0, 255, 0),
                2,
                cv2.LINE_AA,
            )

            # ë¡œê·¸ ì €ì¥ (ì´ˆë‹¹ ìˆ˜ì‹­ë²ˆì´ë¼ë„ ìƒê´€ì—†ìœ¼ë©´ ê·¸ëƒ¥ ë‹¤ ì €ì¥)
            self.log.append(
                {
                    "time": time.time(),
                    "angle": float(angle),
                    "diff": float(diff) if diff is not None else None,
                }
            )

        else:
            self.last_angle = None
            self.last_diff = None

        return av.VideoFrame.from_ndarray(img, format="bgr24")


# ========= Streamlit UI =========
def main():
    st.set_page_config(page_title="ì–¼êµ´ ê°ë„ ë¶„ì„ ë°ëª¨", layout="wide")
    st.title("ğŸ“· ì–¼êµ´ ê°ë„ ë¶„ì„ Â· ê¸°ì¤€ ì‚¬ì§„ê³¼ì˜ ìœ ì‚¬ë„ ì²´í¬")

    st.write(
        """
        - ì™¼ìª½ì—ì„œ **ê¸°ì¤€ ì‚¬ì§„**ì„ ì—…ë¡œë“œí•´ì„œ ê¸°ì¤€ ì–¼êµ´ ê°ë„ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.  
        - ì˜¤ë¥¸ìª½ì— ì¹´ë©”ë¼ë¥¼ ì¼œë©´ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°ë„ì™€ ê¸°ì¤€ ëŒ€ë¹„ ì°¨ì´ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  
        - ì•„ë˜ì—ì„œ **ìŠ¤ëƒ…ìƒ· ì €ì¥ / CSV ë‹¤ìš´ë¡œë“œ**ë„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        """
    )

    if "snapshot_counter" not in st.session_state:
        st.session_state["snapshot_counter"] = 0
    if "last_snapshot_png" not in st.session_state:
        st.session_state["last_snapshot_png"] = None

    col_left, col_right = st.columns(2)

    # ---- ê¸°ì¤€ ì‚¬ì§„ ì—…ë¡œë“œ & ë¶„ì„ ----
    with col_left:
        st.subheader("1ï¸âƒ£ ê¸°ì¤€ ì‚¬ì§„ ì„¤ì •")

        uploaded_file = st.file_uploader(
            "ì–¼êµ´ì´ ì˜ ë‚˜ì˜¨ ê¸°ì¤€ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (jpg, png ë“±)",
            type=["jpg", "jpeg", "png"],
        )

        ref_angle = None
        if uploaded_file is not None:
            if st.button("ê¸°ì¤€ ì‚¬ì§„ ê°ë„ ë¶„ì„í•˜ê¸°"):
                ref_angle = analyze_reference_image(uploaded_file)
                if ref_angle is not None:
                    st.success(f"ê¸°ì¤€ ì–¼êµ´ ê°ë„: {ref_angle:.2f}Â°")
                    st.session_state["ref_angle_value"] = ref_angle

        # ì´ë¯¸ ê³„ì‚°ëœ ê¸°ì¤€ ê°ë„ê°€ ì„¸ì…˜ì— ìˆë‹¤ë©´ í‘œì‹œ
        if "ref_angle_value" in st.session_state:
            st.info(f"í˜„ì¬ ì €ì¥ëœ ê¸°ì¤€ ê°ë„: {st.session_state['ref_angle_value']:.2f}Â°")

    # ---- ì¹´ë©”ë¼ WebRTC ----
    with col_right:
        st.subheader("2ï¸âƒ£ ì¹´ë©”ë¼ë¡œ ì‹¤ì‹œê°„ ë¶„ì„")

        webrtc_ctx = webrtc_streamer(
            key="face-angle-demo",
            mode=WebRtcMode.SENDRECV,
            rtc_configuration=RTC_CONFIGURATION,
            media_stream_constraints={"video": True, "audio": False},
            video_transformer_factory=FaceAngleTransformer,
            async_processing=True,
        )

        # ê¸°ì¤€ ê°ë„ë¥¼ transformerì— ë°˜ì˜
        if webrtc_ctx.video_transformer:
            transformer: FaceAngleTransformer = webrtc_ctx.video_transformer

            if "ref_angle_value" in st.session_state:
                transformer.set_reference_angle(st.session_state["ref_angle_value"])

            # í˜„ì¬ ê°ë„ / ì°¨ì´ ì •ë³´ í‘œì‹œ
            angle_placeholder = st.empty()
            diff_placeholder = st.empty()

            if webrtc_ctx.state.playing:
                # ì´ ë¶€ë¶„ì€ ìŠ¤íŠ¸ë¦¼ë¦¿ì´ ì¬ì‹¤í–‰ë  ë•Œë§ˆë‹¤ ê°±ì‹ ë¨
                current_angle = transformer.last_angle
                current_diff = transformer.last_diff

                if current_angle is not None:
                    angle_placeholder.metric("í˜„ì¬ ì–¼êµ´ ê°ë„", f"{current_angle:.2f}Â°")
                else:
                    angle_placeholder.write("ì–¼êµ´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

                if current_diff is not None and transformer.ref_angle is not None:
                    diff_placeholder.metric(
                        "ê¸°ì¤€ ëŒ€ë¹„ ì°¨ì´",
                        f"{current_diff:+.2f}Â°",
                    )
                elif transformer.ref_angle is None:
                    diff_placeholder.write("ê¸°ì¤€ ê°ë„ê°€ ì•„ì§ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                else:
                    diff_placeholder.write("ì°¨ì´ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")

    # ---- ìŠ¤ëƒ…ìƒ· ì €ì¥ & CSV ë‹¤ìš´ë¡œë“œ ----
    st.subheader("3ï¸âƒ£ ìŠ¤ëƒ…ìƒ· ë° ê¸°ë¡ ì €ì¥")

    if "ref_angle_value" in st.session_state:
        st.write(f"ì‚¬ìš© ì¤‘ì¸ ê¸°ì¤€ ê°ë„: **{st.session_state['ref_angle_value']:.2f}Â°**")

    # webrtc ì»¨í…ìŠ¤íŠ¸ ë‹¤ì‹œ ì‚¬ìš© (ìœ„ì—ì„œ ë§Œë“¤ì—ˆë˜ ê²ƒ)
    webrtc_ctx = st.session_state.get("webrtc_state_face-angle-demo", None)
    # â†‘ ìµœì‹  streamlit-webrtcì—ì„œëŠ” ctxë¥¼ ì„¸ì…˜ì— ìë™ ì €ì¥ ì•ˆ í•  ìˆ˜ë„ ìˆìŒ â†’ ì•„ë˜ì—ì„œ ë‹¤ì‹œ ê°€ì ¸ì˜´
    # í•˜ì§€ë§Œ ìœ„ì—ì„œ ë§Œë“  webrtc_ctxë¥¼ ê·¸ëŒ€ë¡œ ì“°ê³  ì‹¶ìœ¼ë©´ êµ¬ì¡°ë¥¼ í•©ì³ë„ ë¬´ë°©í•¨.

    # ì‹¤ì œë¡œëŠ” ë°”ë¡œ ìœ—ë¶€ë¶„ì—ì„œ ìƒì„±í•œ webrtc_ctxë¥¼ ë‹¤ì‹œ ì‚¬ìš©í•˜ëŠ” ê²Œ ë” í™•ì‹¤í•˜ë¯€ë¡œ,
    # ê°„ë‹¨í•˜ê²Œ ë‹¤ì‹œ í•œ ë²ˆ ê°€ì ¸ì˜¤ëŠ” ë°©ì‹ ëŒ€ì‹ , ìœ„ì—ì„œ ì •ì˜í•œ webrtc_ctxë¥¼ ê·¸ëŒ€ë¡œ ì“°ëŠ” ì„¤ê³„ë„ ê°€ëŠ¥.

    # ì—¬ê¸°ì„œëŠ” ì„¤ëª… ë‹¨ìˆœí™”ë¥¼ ìœ„í•´ ìœ„ìª½ col_rightì˜ webrtc_ctxë¥¼ ë‹¤ì‹œ ì¨ì•¼ í•¨:
    # (Streamlitì—ì„œëŠ” ê°™ì€ run ì•ˆì´ë¯€ë¡œ webrtc_ctx ë³€ìˆ˜ëŠ” ì—¬ì „íˆ ìœ íš¨)

    try:
        transformer = webrtc_ctx.video_transformer  # type: ignore
    except Exception:
        transformer = None

    col1, col2 = st.columns(2)

    with col1:
        if st.button("í˜„ì¬ í™”ë©´ ìŠ¤ëƒ…ìƒ· ì €ì¥"):
            if transformer and transformer.last_frame is not None:
                img_png = encode_image_to_png_bytes(transformer.last_frame)
                st.session_state["last_snapshot_png"] = img_png
                st.session_state["snapshot_counter"] += 1
                st.success("ìŠ¤ëƒ…ìƒ·ì„ ì„ì‹œë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤. ì•„ë˜ì—ì„œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            else:
                st.warning("ì¹´ë©”ë¼ê°€ ì¼œì ¸ ìˆê³ , ì–¼êµ´ì´ ë³´ì´ëŠ” ìƒíƒœì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")

        if st.session_state.get("last_snapshot_png") is not None:
            st.download_button(
                label=f"ë§ˆì§€ë§‰ ìŠ¤ëƒ…ìƒ· PNG ë‹¤ìš´ë¡œë“œ (#{st.session_state['snapshot_counter']})",
                data=st.session_state["last_snapshot_png"],
                file_name=f"snapshot_{st.session_state['snapshot_counter']}.png",
                mime="image/png",
            )

    with col2:
        st.write("ì‹¤ì‹œê°„ ê°ë„ ê¸°ë¡ì„ CSVë¡œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        if transformer and transformer.log:
            # CSV í…ìŠ¤íŠ¸ ìƒì„±
            csv_buffer = StringIO()
            csv_buffer.write("time,angle,diff\n")
            for row in transformer.log:
                csv_buffer.write(
                    f"{row['time']},{row['angle']},{'' if row['diff'] is None else row['diff']}\n"
                )

            csv_data = csv_buffer.getvalue()

            st.download_button(
                label="ì¸¡ì • ê¸°ë¡ CSV ë‹¤ìš´ë¡œë“œ",
                data=csv_data,
                file_name="face_angle_log.csv",
                mime="text/csv",
            )
        else:
            st.info("ì•„ì§ ê¸°ë¡ëœ ê°ë„ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤. ì¹´ë©”ë¼ë¥¼ ì¼œê³  ì–¼êµ´ì„ ë¹„ì¶°ë³´ì„¸ìš”.")


if __name__ == "__main__":
    main()